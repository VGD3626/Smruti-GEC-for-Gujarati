{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1751288008205,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "lpnLbLa99MGD"
   },
   "outputs": [],
   "source": [
    "# RES_FOLDER = \"/content/drive/MyDrive/Smruti-GEC-for-Gujarati/results/human-annotated/\"\n",
    "RES_FOLDER = \"/content/drive/MyDrive/Smruti-GEC-for-Gujarati/results/synthetic/\"\n",
    "res_file = RES_FOLDER + \"cot_with_m1&m2_k1=7_k2=1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2901,
     "status": "ok",
     "timestamp": 1751288011113,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "MHXB6UnUV53r",
    "outputId": "655dc482-670c-4826-bc5c-b7b67231261f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gnTCeej1EUx"
   },
   "source": [
    "# Python2 Installation and Git clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6368,
     "status": "ok",
     "timestamp": 1751288017482,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "6RYI-ZYK0x79",
    "outputId": "2907996d-4483-4ada-b2ed-3ccb481d0d39"
   },
   "outputs": [],
   "source": [
    "!apt -qq update -y\n",
    "!apt -qq install python2 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751288017487,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "yyHFwcJ01DPJ",
    "outputId": "1b45d0bb-fff9-4026-b31e-241c9cb55dde"
   },
   "outputs": [],
   "source": [
    "!python2 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1751288017496,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "qPCzqlVb2POP",
    "outputId": "af0dea2c-3332-47f6-d1ed-5c15d45c7470"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/keisks/m2scorer.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTkVDNd012aY"
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1751288017520,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "DSxrFKKV1dAf"
   },
   "outputs": [],
   "source": [
    "import re, json\n",
    "stopwords = []\n",
    "def GujaratiTokenizer(data, keep_stopwords=True):\n",
    "    data = re.sub(r'([”“.,;:\\'\\\\\"!?%#@*<>|\\+\\-\\(\\)])', r' \\1 ', data)\n",
    "    data = re.sub(r\"   \", ' ', data)\n",
    "    data = re.sub(r'…', \" \", data)\n",
    "    data = re.sub(r'[‘’]', \"'\", data)\n",
    "    data = re.sub(r\"[”“]\", r'\"', data)\n",
    "    data = re.split(r'[ -]', data)\n",
    "    words = []\n",
    "\n",
    "    if not keep_stopwords:\n",
    "        for word in data:\n",
    "            if word and word not in stopwords:\n",
    "                words.append(word)\n",
    "        return words\n",
    "\n",
    "    for i in data:\n",
    "        if i:\n",
    "            words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsIg9-op35Ge"
   },
   "source": [
    "# M$^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751288030947,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "uM4L57K69dgo"
   },
   "outputs": [],
   "source": [
    "def load_json_data(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1751288031269,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "FvqUcylx9OoC"
   },
   "outputs": [],
   "source": [
    "filepath = res_file\n",
    "json_data = load_json_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1751288031286,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "bmJKViky359f"
   },
   "outputs": [],
   "source": [
    "with open('parallel.txt', 'w', encoding='utf-8') as f:\n",
    "    for entry in json_data:\n",
    "        incorrect = entry[\"input\"].strip()\n",
    "        if isinstance(entry[\"reference\"], list):\n",
    "          correct_sentences = [s.strip() for s in entry[\"reference\"]]\n",
    "        else:\n",
    "          correct_sentences = [entry[\"reference\"].strip()]\n",
    "        line = incorrect + ' || ' + ' | '.join(correct_sentences) + '\\n'\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1751288031355,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "2HfC3Zl_38df",
    "outputId": "7248fd7d-d16b-4b22-fd5e-1dcaf6576ac4"
   },
   "outputs": [],
   "source": [
    "with open('pred.txt', 'w', encoding='utf-8') as f:\n",
    "    for entry in json_data:\n",
    "        predicted = entry[\"prediction\"].strip()\n",
    "        predicted = ' '.join(GujaratiTokenizer(predicted))\n",
    "        f.write(predicted + '\\n')\n",
    "\n",
    "print(\"Predicted values written to pred.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1751288031372,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "flsMoJKX96fB"
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "from collections import defaultdict\n",
    "\n",
    "def tokenize_gu(text):\n",
    "    return GujaratiTokenizer(text)\n",
    "\n",
    "def generate_edits(src_tokens, ref_tokens, annotator_id):\n",
    "    matcher = difflib.SequenceMatcher(None, src_tokens, ref_tokens)\n",
    "    edits = []\n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag == 'equal':\n",
    "            continue\n",
    "        corrections = ' '.join(ref_tokens[j1:j2]) if j1 < j2 else '-NONE-'\n",
    "        err_type = {\n",
    "            'replace': 'R:OTHER',\n",
    "            'insert':  'M:OTHER',\n",
    "            'delete':  'U:OTHER'\n",
    "        }[tag]\n",
    "        edits.append(f\"A {i1} {i2}|||{err_type}|||{corrections}|||REQUIRED|||-NONE-|||{annotator_id}\")\n",
    "    return edits\n",
    "\n",
    "def generate_m2_from_parallel(input_path, output_path=\"gold.m2\"):\n",
    "    sentence_blocks = []\n",
    "\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "    for line in lines:\n",
    "        src_text, refs_part = line.split('||', 1)\n",
    "        src_tokens = tokenize_gu(src_text)\n",
    "        refs = [r.strip() for r in refs_part.split('|') if r.strip()]\n",
    "\n",
    "        s_line = f\"S {' '.join(src_tokens)}\"\n",
    "        all_edits = []\n",
    "\n",
    "        for ann_id, ref in enumerate(refs):\n",
    "            ref_tokens = tokenize_gu(ref)\n",
    "            edits = generate_edits(src_tokens, ref_tokens, annotator_id=str(ann_id))\n",
    "            if not edits:\n",
    "                all_edits.append(f\"A -1 -1|||noop|||-NONE-|||REQUIRED|||-NONE-|||{ann_id}\")\n",
    "            else:\n",
    "                all_edits.extend(edits)\n",
    "\n",
    "        sentence_blocks.append((s_line, all_edits))\n",
    "\n",
    "    # Write all at once\n",
    "    with open(output_path, 'w', encoding='utf-8') as out:\n",
    "        for s_line, edits in sentence_blocks:\n",
    "            out.write(s_line + \"\\n\")\n",
    "            for edit in edits:\n",
    "                out.write(edit + \"\\n\")\n",
    "            out.write(\"\\n\")\n",
    "\n",
    "    print(f\"Generated {output_path} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1751288031645,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "X-w3yMdJ-jy1",
    "outputId": "ef927be7-a98b-4fe8-bb4e-4e07969192b3"
   },
   "outputs": [],
   "source": [
    "generate_m2_from_parallel(\"parallel.txt\", \"hyp.m2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFdOoWJs_80T"
   },
   "source": [
    "# _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751288034146,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "OBGV4iLy_Lns",
    "outputId": "71199eea-fcb5-48c9-f892-51fcba6f1027"
   },
   "outputs": [],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20720,
     "status": "ok",
     "timestamp": 1751288056379,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "a4GH0Ns8_Qsk",
    "outputId": "3f2fbb45-0251-4da8-fbe2-427058b6876a"
   },
   "outputs": [],
   "source": [
    "!python2 /content/m2scorer/scripts/m2scorer.py /content/pred.txt /content/hyp.m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZWcTBBbSnDn"
   },
   "source": [
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9741,
     "status": "aborted",
     "timestamp": 1751288017648,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "ATS9swo7_uT0"
   },
   "outputs": [],
   "source": [
    "# prompt: Write the code to compare two json results files, by printing missmatched predictions,\n",
    "# 29.86 32.47 32.74 33.21 32.15\n",
    "def compare_predictions(file1_path, file2_path):\n",
    "    data1 = load_json_data(file1_path)\n",
    "    data2 = load_json_data(file2_path)\n",
    "\n",
    "    mismatched_predictions = []\n",
    "\n",
    "    for entry1, entry2 in zip(data1, data2):\n",
    "        if entry1[\"prediction\"].strip() != entry2[\"prediction\"].strip():\n",
    "            mismatched_predictions.append({\n",
    "                \"input\": entry1[\"input\"].strip(),\n",
    "                \"prediction_file1\": entry1[\"prediction\"].strip(),\n",
    "                \"prediction_file2\": entry2[\"prediction\"].strip(),\n",
    "                \"reference\": entry1[\"reference\"] if isinstance(entry1[\"reference\"], list) else entry1[\"reference\"]\n",
    "            })\n",
    "\n",
    "    if not mismatched_predictions:\n",
    "        print(\"All predictions match between the two files.\")\n",
    "    else:\n",
    "        print(\"Mismatched predictions found:\")\n",
    "        for mismatch in mismatched_predictions:\n",
    "            print(f\"Input: {mismatch['input']}\")\n",
    "            print(f\"Prediction from file 1: {mismatch['prediction_file1']}\")\n",
    "            print(f\"Prediction from file 2: {mismatch['prediction_file2']}\")\n",
    "            print(f\"Reference(s): {mismatch['reference']}\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "# Example usage: Replace with your actual file paths\n",
    "file1_path = RES_FOLDER + \"cot_with_m1&m2_k1=5_k2=2.json\" # Assuming this is the first file\n",
    "# Create a dummy second file for demonstration if needed, or use your actual second file\n",
    "# For this example, let's assume you have another results file named \"another_results.json\"\n",
    "# If you don't have a second file, you can duplicate the first one for testing:\n",
    "# !cp {file1_path} {RES_FOLDER}/another_results.json\n",
    "# file2_path = RES_FOLDER + \"another_results.json\"\n",
    "\n",
    "# Replace with the actual path to your second results file\n",
    "file2_path = RES_FOLDER + \"cot_with_m1_k1=3.json\" # Replace with your actual file path\n",
    "\n",
    "compare_predictions(file1_path, file2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9741,
     "status": "aborted",
     "timestamp": 1751288017649,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "yyDJlqbnvZQQ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def count_total_tokens(file_path):\n",
    "    total_tokens = 0\n",
    "\n",
    "    # Determine file extension\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "\n",
    "    if ext == \".json\":\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for entry in data:\n",
    "            # Tokenize 'input'\n",
    "            input_text = entry.get(\"input\", \"\")\n",
    "            total_tokens += len(GujaratiTokenizer(input_text))\n",
    "\n",
    "            # Tokenize 'reference'\n",
    "            references = entry.get(\"reference\", [])\n",
    "            if isinstance(references, str):\n",
    "                references = [references]\n",
    "\n",
    "            for ref in references:\n",
    "                total_tokens += len(GujaratiTokenizer(ref))\n",
    "\n",
    "    elif ext == \".txt\":\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:  # Skip empty lines\n",
    "                    total_tokens += len(GujaratiTokenizer(line))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "\n",
    "    return total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9741,
     "status": "aborted",
     "timestamp": 1751288017650,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "1StOT_qhg0nQ"
   },
   "outputs": [],
   "source": [
    "count_total_tokens(\"/content/drive/MyDrive/Smruti-GEC-for-Gujarati/data/validation_set.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9740,
     "status": "aborted",
     "timestamp": 1751288017651,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "741j13cahoU-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0gnTCeej1EUx",
    "xTkVDNd012aY",
    "WsIg9-op35Ge"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
