{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1750529659194,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "g7arzRIRAYg-"
   },
   "outputs": [],
   "source": [
    "RES_FOLDER = \"/content/drive/MyDrive/Smruti-GEC-for-Gujarati/results/synthetic/\"\n",
    "res_file = RES_FOLDER + \"zs-gpt-4o-mini_results_2.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89Zu3_6F17Io"
   },
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11680,
     "status": "ok",
     "timestamp": 1750529670883,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "tZrjFcsw8o-r"
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4164,
     "status": "ok",
     "timestamp": 1750529675055,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "e8T9Craj4OQT"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from nltk.translate.gleu_score import sentence_gleu, corpus_gleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q640mubqY4Hu"
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750531089987,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "j27CmqSnEnyX"
   },
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "def GujaratiTokenizer(data, keep_stopwords=True):\n",
    "    data = re.sub(r'([”“.,;:\\'\\\\\"!?%#@*<>|\\+\\-\\(\\)])', r' \\1 ', data)\n",
    "    data = re.sub(r\"   \", ' ', data)\n",
    "    data = re.sub(r'…', \" \", data)\n",
    "    data = re.sub(r'[‘’]', \"'\", data)\n",
    "    data = re.sub(r\"[”“]\", r'\"', data)\n",
    "    data = re.split(r'[ -]', data)\n",
    "    words = []\n",
    "\n",
    "    if not keep_stopwords:\n",
    "        for word in data:\n",
    "            if word and word not in stopwords:\n",
    "                words.append(word)\n",
    "        return words\n",
    "\n",
    "    for i in data:\n",
    "        if i:\n",
    "            words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750531096323,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "iXgyZsMWvS2L",
    "outputId": "e57bc45d-2fae-4d50-b253-190d405f00da"
   },
   "outputs": [],
   "source": [
    "def calculate_sentence_gleu(predicted_sentence, correct_sentences):\n",
    "  \"\"\"Calculates GLEU for a single sentence pair.\n",
    "\n",
    "  Args:\n",
    "    predicted_sentence: The predicted sentence string.\n",
    "    correct_sentences: A list of correct sentence strings.\n",
    "\n",
    "  Returns:\n",
    "    The sentence-level GLEU score.\n",
    "  \"\"\"\n",
    "  tokenized_predicted = GujaratiTokenizer(predicted_sentence)\n",
    "  tokenized_correct = [GujaratiTokenizer(s) for s in correct_sentences]\n",
    "  return sentence_gleu(tokenized_correct, tokenized_predicted)\n",
    "\n",
    "predicted = \"મેં તેને સેક્રેટરી દ્વારા કહેવરવ્યું છે.\"\n",
    "correct = [\"મેં તેને સેક્રેટરી દ્વારા કહેવરાવ્યું છે.\",\n",
    "        \"મેં તેને સેક્રેટરી દ્વારા કહેવડાવ્યું છે.\"]\n",
    "\n",
    "gleu_score = calculate_sentence_gleu(predicted, correct)\n",
    "print(f\"Sentence GLEU score: {gleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_tMqM3z7Ia-"
   },
   "source": [
    "# GLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1750532832209,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "odZyqh6d6HZC"
   },
   "outputs": [],
   "source": [
    "def load_json_data(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def calculate_avg_gleu(data):\n",
    "    total_gleu_score = 0\n",
    "    num_sentences = 0\n",
    "\n",
    "    for entry in data:\n",
    "        predicted = entry[\"prediction\"]\n",
    "        correct_sentences = entry[\"reference\"]\n",
    "        tokenized_predicted = GujaratiTokenizer(predicted)\n",
    "        if isinstance(correct_sentences, list):\n",
    "          tokenized_correct = [GujaratiTokenizer(s) for s in correct_sentences]\n",
    "        else:\n",
    "          tokenized_correct = GujaratiTokenizer(correct_sentences)\n",
    "        # print(tokenized_predicted)\n",
    "        # print(tokenized_correct)\n",
    "        gleu_score = sentence_gleu(tokenized_correct, tokenized_predicted)\n",
    "        total_gleu_score += gleu_score\n",
    "        num_sentences += 1\n",
    "\n",
    "    return total_gleu_score / num_sentences if num_sentences else 0\n",
    "\n",
    "def calculate_corpus_gleu(data):\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    for entry in data:\n",
    "        predicted = entry[\"prediction\"]\n",
    "        correct_sentences = entry[\"reference\"]\n",
    "        tokenized_predicted = GujaratiTokenizer(predicted)\n",
    "        if isinstance(correct_sentences, list):\n",
    "          tokenized_correct = [GujaratiTokenizer(s) for s in correct_sentences]\n",
    "        else:\n",
    "          tokenized_correct = GujaratiTokenizer(correct_sentences)\n",
    "        references.append(tokenized_correct)\n",
    "        hypotheses.append(tokenized_predicted)\n",
    "\n",
    "    return corpus_gleu(references, hypotheses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0sScggN7F0d"
   },
   "source": [
    "# _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2544,
     "status": "ok",
     "timestamp": 1750532837206,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "PZjm7zwx92nt",
    "outputId": "356052f5-cbde-4f4b-b5ff-c29af698f25f"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    filepath = res_file\n",
    "    json_data = load_json_data(filepath)\n",
    "    overall_gleu = calculate_avg_gleu(json_data)\n",
    "    corpus_gleu_score = calculate_corpus_gleu(json_data)\n",
    "\n",
    "    print(f\"Sentence-level GLEU score (average): {overall_gleu:.8f}\")\n",
    "    print(f\"Corpus-level GLEU score: {corpus_gleu_score:.8f}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: JSON file not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750529691523,
     "user": {
      "displayName": "Vrund Dobariya",
      "userId": "02667739450293044164"
     },
     "user_tz": -330
    },
    "id": "9ZSBPmW25ux5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOzRnuLeMAOcClnAZOE2vO/",
   "collapsed_sections": [
    "89Zu3_6F17Io",
    "Q640mubqY4Hu",
    "6_tMqM3z7Ia-"
   ],
   "mount_file_id": "1Lf_xHK6qHwKOtGGmvm1CvWEPCLnIAEuJ",
   "provenance": [
    {
     "file_id": "1OMhFJucgbHoIbb2Ukl0dPRnMU0BLxChx",
     "timestamp": 1750309688198
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
